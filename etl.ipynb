{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_data = \"./data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType as R, StructField,DecimalType as Dec, DoubleType as Dbl,LongType as Long, StringType as Str, IntegerType as Int, DateType as Date \n",
    "songsSchema = R([\n",
    "    StructField(\"num_songs\",Int()),\n",
    "    StructField(\"artist_id\",Str()),\n",
    "    StructField(\"artist_latitude\",Dec()),\n",
    "    StructField(\"artist_longitude\",Dec()),\n",
    "    StructField(\"artist_location\",Str()),\n",
    "    StructField(\"artist_name\",Str()),\n",
    "    StructField(\"song_id\",Str()),\n",
    "    StructField(\"title\",Str()),\n",
    "    StructField(\"duration\",Dbl()),\n",
    "    StructField(\"year\",Int()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "song_data = input_data + \"song_data/*/*/*/*.json\"\n",
    "df = spark.read.json(song_data, schema=songsSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- num_songs: integer (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- artist_latitude: decimal(10,0) (nullable = true)\n",
      " |-- artist_longitude: decimal(10,0) (nullable = true)\n",
      " |-- artist_location: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"songs_data_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "songs_table = spark.sql('''\n",
    "    SELECT DISTINCT song_id, title, artist_id, year, duration\n",
    "    FROM songs_data_table\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs table schema:\n",
      "\n",
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- duration: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Songs table schema:\\n\")\n",
    "songs_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(song_id='SOBBXLX12A58A79DDA', title='Erica (2005 Digital Remaster)', artist_id='AREDBBQ1187B98AFF5', year=0, duration=138.63138)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#songs_table.write.parquet(output_data + \"songs_table.parquet\",\n",
    "#                          mode = \"overwrite\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "logsSchema = R([\n",
    "        StructField(\"artist\", Str()), \n",
    "        StructField('auth', Str()),\n",
    "        StructField('firstName', Str()),\n",
    "        StructField('gender', Str()),\n",
    "        StructField('itemInSession', Int()),\n",
    "        StructField('lastName', Str()),\n",
    "        StructField('length', Dbl()),\n",
    "        StructField('level', Str()),\n",
    "        StructField('location', Str()),\n",
    "        StructField('method', Str()),\n",
    "        StructField('page', Str()),\n",
    "        StructField('registration', Dec()),\n",
    "        StructField('sessionId', Int()),\n",
    "        StructField('song', Str()),\n",
    "        StructField('status', Int()),\n",
    "        StructField('ts', Long()),\n",
    "        StructField('userAgent', Str()),\n",
    "        StructField('userId', Int()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading song_data from ./data/log_data/*/*/*.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_data = input_data + \"log_data/*/*/*.json\"\n",
    "print(\"Reading song_data from {}\\n\".format(log_data))\n",
    "# read log data file\n",
    "df = spark.read.json(log_data)\n",
    "\n",
    "# filter by actions for song plays\n",
    "# If I specify the schema, all empties are None...\n",
    "df = df.filter(df.page=='NextSong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"logs_data_table\")\n",
    "    # extract columns for users table    \n",
    "users_table = spark.sql('''\n",
    "        SELECT DISTINCT userId as user_id, firstName as first_name, lastName as last_name, gender, level\n",
    "        FROM logs_data_table\n",
    "    ''')\n",
    "users_table = users_table.dropDuplicates([\"user_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id='51', first_name='Maia', last_name='Burke', gender='F', level='free')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_table.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "users_table.createOrReplaceTempView(\"users\")\n",
    "count_users = spark.sql('''\n",
    "    SELECT *\n",
    "    FROM users\n",
    "    WHERE user_id='16'\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(user_id='16', first_name='Rylan', last_name='George', gender='M', level='paid')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_users.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create timestamp column from original timestamp column\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "convert_ts = udf(lambda time: datetime.fromtimestamp((time/1000.0)), TimestampType())\n",
    "get_datetime = udf(lambda time: datetime.fromtimestamp((time/1000.0)), Date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: double (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_ts = df.withColumn(\"date\",get_datetime(\"ts\"))\n",
    "\n",
    "clean_ts = clean_ts.withColumn(\"ts\",convert_ts(\"ts\"))\n",
    "clean_ts.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(artist='Harmonia', auth='Logged In', firstName='Ryan', gender='M', itemInSession=0, lastName='Smith', length=655.77751, level='free', location='San Jose-Sunnyvale-Santa Clara, CA', method='PUT', page='NextSong', registration=1541016707796.0, sessionId=583, song='Sehr kosmisch', status=200, ts=datetime.datetime(2018, 11, 15, 0, 30, 26, 796000), userAgent='\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/36.0.1985.125 Chrome/36.0.1985.125 Safari/537.36\"', userId='26', date=datetime.date(2018, 11, 15))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-----+---+----+-------+----+\n",
      "|          start_time|year|month|day|week|weekday|hour|\n",
      "+--------------------+----+-----+---+----+-------+----+\n",
      "|2018-11-15 00:30:...|2018|   11| 15|  46|    Thu|   0|\n",
      "|2018-11-15 00:41:...|2018|   11| 15|  46|    Thu|   0|\n",
      "|2018-11-15 00:45:...|2018|   11| 15|  46|    Thu|   0|\n",
      "|2018-11-15 03:44:...|2018|   11| 15|  46|    Thu|   3|\n",
      "|2018-11-15 05:48:...|2018|   11| 15|  46|    Thu|   5|\n",
      "+--------------------+----+-----+---+----+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# extract columns to create time table\n",
    "clean_ts.createOrReplaceTempView(\"clean\")\n",
    "time_table = spark.sql('''\n",
    "    SELECT ts AS start_time, \n",
    "        date_format(date,'YYYY') AS year,\n",
    "        date_format(date,'MM') AS month,\n",
    "        date_format(date,'dd') AS day,\n",
    "        date_format(date,'w') AS week,\n",
    "        date_format(ts,'E') AS weekday,\n",
    "        HOUR(ts) AS hour\n",
    "    FROM clean\n",
    "    LIMIT 5\n",
    "''')\n",
    "time_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in song data to use for songplays table\n",
    "song_df = input_data + \"song_data/*/*/*/*.json\"\n",
    "song_df = spark.read.json(song_data, schema=songsSchema)\n",
    "song_df.createOrReplaceTempView(\"songs_data_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "artists_table = spark.sql('''\n",
    "    SELECT DISTINCT artist_id, artist_name AS name, artist_location AS location, artist_latitude AS latitude, artist_longitude AS longitude\n",
    "    FROM songs_data_table\n",
    "''')\n",
    "artists_table.createOrReplaceTempView(\"artists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+-----------+\n",
      "|          start_time|user_id|level|           song_id|         artist_id|session_id|            location|          user_agent|songplay_id|\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+-----------+\n",
      "|2018-11-21 21:56:...|     15| paid|SOZCTXZ12AB0182364|AR5KOSW1187FB35FF4|       818|Chicago-Napervill...|\"Mozilla/5.0 (X11...|          0|\n",
      "+--------------------+-------+-----+------------------+------------------+----------+--------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "songplays_table = spark.sql('''\n",
    "    SELECT \n",
    "        l.ts AS start_time,\n",
    "        l.userId AS user_id,\n",
    "        l.level,\n",
    "        s.song_id,\n",
    "        a.artist_id,\n",
    "        l.sessionId AS session_id,\n",
    "        l.location,\n",
    "        l.userAgent AS user_agent\n",
    "    FROM clean AS l\n",
    "    JOIN songs_data_table AS s \n",
    "    ON (l.song = s.title AND l.artist = s.artist_name)  \n",
    "    JOIN artists AS a ON a.artist_id=s.artist_id\n",
    "    LIMIT 5\n",
    "''')\n",
    "songplays_table = songplays_table.withColumn(\"songplay_id\", monotonically_increasing_id())\n",
    "songplays_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
